# Aprendizado de M√°quina e Modelagem Estat√≠stica em R
> Trabalho realizado para a disciplina: Linguagem R, no curso de Intelig√™ncia Artifical Aplicada da UFPR

## Vis√£o Geral

Este projeto consiste em duas tarefas distintas de an√°lise de dados utilizando R, focando em **Classifica√ß√£o** (Tarefa 1) e **Regress√£o** (Tarefa 2). O objetivo √© comparar m√©todos estat√≠sticos tradicionais com algoritmos de aprendizado de m√°quina (*machine learning*) utilizando a estrutura do pacote `caret`.

O projeto avalia o desempenho dos modelos utilizando m√©tricas como Acur√°cia e Kappa para classifica√ß√£o, e R^2 (Coeficiente de Determina√ß√£o) e S_{yx} (Erro Padr√£o da Estimativa) para regress√£o.

---

## üõ† Pr√©-requisitos

Para executar estes scripts, s√£o necess√°rios os seguintes pacotes R. Os scripts utilizam o `caret` para o pipeline de treinamento e bibliotecas espec√≠ficas para cada algoritmo.

```r
install.packages(c("caret", "e1071", "randomForest", "kernlab", "neuralnet", "mlbench"))

```

* **caret:** *Classification And REgression Training* (interface unificada).
* **e1071:** Fun√ß√µes diversas (necess√°rio para SVM e depend√™ncias).
* **randomForest:** Implementa√ß√£o do algoritmo Random Forest (Florestas Aleat√≥rias).
* **kernlab:** Aprendizado de m√°quina baseado em Kernel (utilizado para SVM).
* **neuralnet:** Treinamento de redes neurais (utilizado na Tarefa 2).
* **mlbench:** Problemas de *Benchmark* de Aprendizado de M√°quina (fonte do conjunto de dados *Satellite*).

---

## üìÇ Estrutura do Projeto

### 1. Tarefa 1: Classifica√ß√£o de Imagens de Sat√©lite (`T1.r`)

Este script resolve um problema de classifica√ß√£o utilizando dados multiespectrais para identificar tipos de solo e cultivo.

* **Conjunto de Dados:** `Satellite` da biblioteca `mlbench`.
* **Vari√°veis Utilizadas:** `x.17`, `x.18`, `x.19`, `x.20` (bandas espectrais).
* **Alvo (Target):** `classes` (Fator com 6 n√≠veis: solo vermelho, cultivo de algod√£o, solo cinza, solo cinza √∫mido, restolho de vegeta√ß√£o, solo cinza muito √∫mido).
* **Divis√£o dos Dados:** 80% Treino / 20% Teste utilizando `createDataPartition`.


#### Modelos Implementados:

1. **Random Forest (`rf`)**: M√©todo de aprendizado *ensemble* (conjunto) utilizando √°rvores de decis√£o.
2. **Support Vector Machine (`svmRadial`)**: SVM com kernel de Fun√ß√£o de Base Radial.
3. **Neural Network (`nnet`)**: Rede neural *feed-forward*.

#### üìä Resultados da Tarefa 1

Com base nos logs de execu√ß√£o, os modelos tiveram o seguinte desempenho no conjunto de teste:

| Modelo | Acur√°cia | Kappa | Notas |
| --- | --- | --- | --- |
| **SVM (Radial)** | **0.8707** | **0.8399** | Melhor desempenho geral.
| **Random Forest** | **0.8419** | **0.8047** | Desempenho forte, ligeiramente abaixo do SVM.
| **Neural Network** | **0.7998** | **0.7510** | Exigiu itera√ß√µes significativas para convergir.

> **Observa√ß√£o:** O modelo SVM apresentou a maior acur√°cia geral e estat√≠stica Kappa, sugerindo ser o classificador mais robusto para a distribui√ß√£o espec√≠fica destes dados espectrais.

---

### 2. Tarefa 2: Regress√£o de Volume Florestal (`T2.r`)

Este script resolve um problema de regress√£o para prever o volume de madeira com base em medidas das √°rvores.

* **Conjunto de Dados:** Externo (`Volumes.csv`).
* **Vari√°veis:** `DAP` (Di√¢metro √† Altura do Peito), `HT` (Altura Total).
* **Alvo (Target):** `VOL` (Volume).
* **M√©tricas Personalizadas:**
* **R^2:** Coeficiente de Determina√ß√£o (Explica a vari√¢ncia).
* **S_{yx}:** Erro Padr√£o da Estimativa (Erro absoluto).
* **S_{yx}\%:** Erro Padr√£o em porcentagem relativo √† m√©dia.



#### Modelos Implementados:

1. **Random Forest (`rf`)**: Ensemble de √°rvores de regress√£o.
2. **Support Vector Machine (`svmRadial`)**: Regress√£o baseada em kernel.
3. **Neural Network (`neuralnet`)**: Perceptron multicamadas para regress√£o.
4. **Modelo SPURR (Alom√©trico)**: Uma equa√ß√£o florestal n√£o linear tradicional definida como VOL \approx b_0 + b_1 \cdot DAP^2 \cdot HT.

#### üìä Resultados da Tarefa 2

Compara√ß√£o de desempenho nos dados de teste:

| Modelo | R^2 (Maior √© melhor) | S_{yx} (Menor √© melhor) |
| --- | --- | --- |
| **Neural Network** | **0.8824** | **0.1295** |
| Random Forest | 0.8535 | 0.1445 |
| SVM (Radial) | 0.8484 | 0.1470 |
| SPURR (Alom√©trico) | 0.8356 | 0.1531 |

> **Observa√ß√£o:** A **Neural Network** (Rede Neural) superou tanto as alternativas de aprendizado de m√°quina quanto a equa√ß√£o tradicional SPURR, alcan√ßando o maior R^2 e o menor erro (S_{yx}). O modelo tradicional SPURR serviu como base (baseline), mas obteve a menor precis√£o entre os m√©todos testados.

---

## üöÄ Como Executar

1. Garanta que voc√™ tenha uma conex√£o ativa com a internet (para baixar o CSV da Tarefa 2 e os pacotes).
2. Abra seu console R ou RStudio.
3. Defina seu diret√≥rio de trabalho para o local dos scripts.
4. Execute o comando `source` para a tarefa desejada:

```r
# Executar Tarefa 1 (Classifica√ß√£o)
source("T1.r")

# Executar Tarefa 2 (Regress√£o)
source("T2.r")

```

---

## üìù Notas T√©cnicas

* **Reprodutibilidade:** Ambos os scripts utilizam `set.seed(7)` para garantir que a divis√£o dos dados e a inicializa√ß√£o dos modelos sejam reprodut√≠veis.
* **Pr√©-processamento:** A Tarefa 2 calcula explicitamente m√©tricas de erro personalizadas manualmente dentro das fun√ß√µes do c√≥digo (`calcular_r2`, `calcular_syx`, e `calcular_syx_percentual`) ao inv√©s de depender apenas dos padr√µes do `caret`.
* **Converg√™ncia:** A rede neural na Tarefa 1 utilizou o m√©todo `nnet` (via caret) e exibiu logs extensos de itera√ß√£o, indicando que exigiu muitas √©pocas para minimizar a fun√ß√£o de erro em compara√ß√£o com os outros modelos .
